{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.spikingjelly.spikingjelly.datasets.n_mnist import NMNIST\n",
    "from utils.spikingjelly.spikingjelly.datasets import play_frame\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import display, clear_output\n",
    "from typing import cast\n",
    "from utils.networks import STDPNet, DiehlAndCook2015, Mozafari2018\n",
    "from utils.dataclasses import DistInfo, ExpInfo\n",
    "from utils.trainer import train_Mozafari\n",
    "from utils.visual import draw_weight_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deprecated code for mnist\n",
    "# FILE_LIST = \"MNIST/raw/train-images-idx3-ubyte MNIST/raw/train-labels-idx1-ubyte MNIST/raw/t10k-images-idx3-ubyte MNIST/raw/t10k-labels-idx1-ubyte\".split()\n",
    "# arrays:list[np.ndarray] = []\n",
    "\n",
    "# for fname in FILE_LIST:\n",
    "#     with open(fname,'rb') as f:\n",
    "#         arrays.append(mnist.parse_idx(f))\n",
    "# assert len(arrays) == 4\n",
    "# train_imgs, train_labels, test_imgs, test_labels = arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpInfo.use_cuda = True\n",
    "w_min, w_max, w_mean, w_std = 0., 1., 0.5, 0.01\n",
    "tau_pre, tau_post = 2., 2.\n",
    "N_in, N_hidden, N_out = 2*34*34, 10, 10\n",
    "T = 64\n",
    "batch_size = 1\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/download'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mNMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# test_set = NMNIST(\"data/\",train=False, data_type=\"frame\", frames_number=T, split_by=\"number\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/STDP-verification/utils/spikingjelly/spikingjelly/datasets/n_mnist.py:31\u001b[0m, in \u001b[0;36mNMNIST.__init__\u001b[0;34m(self, root, train, data_type, frames_number, split_by, duration, custom_integrate_function, custom_integrated_frames_dir_name, transform, target_transform)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mThe N-MNIST dataset, which is proposed by `Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades <https://www.frontiersin.org/articles/10.3389/fnins.2015.00437/full>`_.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mRefer to :class:`spikingjelly.datasets.NeuromorphicDatasetFolder` for more details about params information.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_integrate_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_integrated_frames_dir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/STDP-verification/utils/spikingjelly/spikingjelly/datasets/__init__.py:750\u001b[0m, in \u001b[0;36mNeuromorphicDatasetFolder.__init__\u001b[0;34m(self, root, train, data_type, frames_number, split_by, duration, custom_integrate_function, custom_integrated_frames_dir_name, transform, target_transform)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    747\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis dataset can not be downloaded by SpikingJelly, please download [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] manually and put files at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 750\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMkdir [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to save downloaded files.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    752\u001b[0m     resource_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_url_md5()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/download'"
     ]
    }
   ],
   "source": [
    "train_set = NMNIST(\"data/\",train=True, data_type=\"frame\", frames_number=T, split_by=\"number\")\n",
    "# test_set = NMNIST(\"data/\",train=False, data_type=\"frame\", frames_number=T, split_by=\"number\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_frame(train_set[15000][0], save_gif_to=\"data_sample.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.isfile(\"saved.net\"):\n",
    "    with open(\"saved.net\", 'rb') as f:\n",
    "        M2018_state_dict = torch.load(f)\n",
    "\n",
    "    net = Mozafari2018()\n",
    "    net.load_state_dict(M2018_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train_Mozafari()\n",
    "fig, axes = plt.subplots(len(Mozafari2018.draw_ids),1)\n",
    "fig.set_size_inches(15, 15)\n",
    "fig.suptitle(f\"0-th iteration\")\n",
    "d_handle = display(fig, display_id=True)\n",
    "assert d_handle is not None\n",
    "\n",
    "for step, ret in enumerate(trainer, start=1):\n",
    "    for axe, img in zip(axes, ret):\n",
    "        draw_weight_map(fig, axe, img)\n",
    "    fig.suptitle(f\"{step}-th iteration\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"out_img/{step:010d}.png\")\n",
    "    d_handle.update(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = [\"cpu\", \"cuda\"][torch.cuda.is_available()]\n",
    "torch.manual_seed(0)\n",
    "do_train = False\n",
    "\n",
    "# plt.style.use(['science'])\n",
    "\n",
    "w_info = DistInfo(w_min, w_max, w_mean, w_std)\n",
    "net:STDPNet = cast(STDPNet, DiehlAndCook2015(2*34*34, N_hidden, tau_pre, tau_post, w_info).to(device))\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.)\n",
    "\n",
    "# Make figure to plot\n",
    "fig = plt.figure(figsize=(15, 3*len(net.draw_ids)))\n",
    "fig.suptitle(f\"0-th iteration\")\n",
    "\n",
    "axes = []\n",
    "caxes = []\n",
    "\n",
    "# Subplot ops.\n",
    "for i, draw_id in enumerate(net.draw_ids):\n",
    "    axes.append(fig.add_subplot(len(net.draw_ids),1,i+1)) # generate new subplot.\n",
    "    pc = axes[-1].pcolor(net.draw_weights(id=draw_id)) # make sub ax for color-number map.\n",
    "    div = make_axes_locatable(axes[-1]) # get division of the subplot.\n",
    "    caxes.append(div.append_axes(\"right\", size=\"5%\", pad=0.05)) # new ax for color bar\n",
    "    fig.colorbar(pc, caxes[-1]) # make colorbar.\n",
    "fig.tight_layout() # fit plots to layout\n",
    "d_handle = display(fig, display_id=True) # jupyter display output\n",
    "assert d_handle is not None # display handle must be valid.\n",
    "\n",
    "with torch.no_grad():\n",
    "    frame = torch.zeros((batch_size, 2*34, 34), requires_grad=False, device=device) # *2 for ON, OFF events\n",
    "    loader = iter(train_loader)\n",
    "    for i, (frames, label) in enumerate(loader, start=1):\n",
    "        for t in range(T):\n",
    "            assert frames.shape == (batch_size,64,2,34,34), f\"{frames.shape}\"\n",
    "            optimizer.zero_grad()\n",
    "            # out_spike.append(net(in_spike[t]))\n",
    "            frame.fill_(0)\n",
    "            frame[:,::2,:] = torch.tensor(frames[:,t,0])\n",
    "            frame[:,1::2,:] = torch.tensor(frames[:,t,1])\n",
    "            net(frame.reshape(batch_size,-1))\n",
    "            \n",
    "            for learner in net.learners:\n",
    "                learner.step(on_grad=True)\n",
    "            optimizer.step()\n",
    "            net.post_optim()\n",
    "            # weight.append(net[0].weight.data.clone())\n",
    "            # trace_pre.append(learner.trace_pre)\n",
    "            # trace_post.append(learner.trace_post)\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            fig.suptitle(f\"{i}-th iteration\")\n",
    "            for i, draw_id in enumerate(net.draw_ids):\n",
    "                pc = axes[i].pcolor(net.draw_weights(id=draw_id))\n",
    "                fig.colorbar(pc, caxes[i])\n",
    "            d_handle.update(fig)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
